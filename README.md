<h1>
<br>AI_Course_Projects
</h1>

---

## ğŸ“’ Table of Contents
- [ğŸ“’ Table of Contents](#-table-of-contents)
- [ğŸ“ Overview](#-overview)
- [ğŸ“‚ Project Structure](#-project-structure)
- [ğŸ” Details of Codes](#-details-of-codes)
- [ğŸš€ Getting Started](#-getting-started)
- [ğŸ¤ Collaborators](#-collaborators)


---
## ğŸ“ Overview

Welcome to the AI Course Projects repository! This repository serves as a collection of projects completed as part of an AI course. Each project demonstrates various concepts, algorithms, and techniques in the field of artificial intelligence. In this repository, you will find a diverse range of AI projects that cover topics such as Markov Decision Process, reinforcement learning, and minimax algorithms. These projects are designed to provide hands-on experience and insight into the practical application of AI concepts.

---


## ğŸ“‚ Project Structure

 * [MDP](./MDP)
 * [Minimax](./Minimax)
 * [RL](./RL)
 * [README.md](./README.md)

Each project directory contains its own README with project-specific details, instructions, and explanations.

---

## ğŸ” Details of Codes

### [MDP](./MDP)
A Markov Decision Process (MDP) is a mathematical framework used to model decision-making in situations where an agent interacts with an environment to achieve specific goals. MDPs are widely applied in the field of artificial intelligence and reinforcement learning. MDPs are a foundational concept in reinforcement learning, and understanding them is essential for developing intelligent agents that can make optimal decisions in uncertain environments.

### [Minimax](./Minimax)
The Minimax algorithm is a decision-making approach used in two-player zero-sum games, where one player's gain is the other player's loss. It's commonly applied in game playing scenarios like chess, tic-tac-toe, and more. The Minimax algorithm aims to find the best move for the current player while assuming that the opponent will make optimal moves to minimize the current player's potential gain. The Minimax algorithm assumes that both players play optimally, considering the best moves from their perspective. It works well for deterministic games with a relatively small game tree. However, in more complex games, the game tree can become too large to traverse fully, leading to performance issues. In practice, optimizations like alpha-beta pruning are often applied to reduce the number of nodes evaluated, making the Minimax algorithm more feasible for larger game trees.

### [RL](./RL)
Value Iteration is a dynamic programming algorithm used in Reinforcement Learning (RL) to solve Markov Decision Processes (MDPs) and find the optimal policy for an agent. MDPs provide a formal framework for decision-making in uncertain environments. The goal of Value Iteration is to iteratively estimate the optimal value function and, subsequently, the optimal policy.

---
## ğŸš€ Getting Started

### âœ”ï¸ Requirements

Before you begin, ensure that you have the packages in `requirements.txt` installed.

### ğŸ“¦ Installation

1. Clone the AI_Course_Projects repository:
```sh
git clone https://github.com/audrina-ebrahimi/AI_Course_Projects.git
```

2. Change to the project directory:
```sh
cd AI_Course_Projects
```

3. Install the dependencies:
```sh
pip install -r ./requirements.txt
```

### ğŸ® Using CIFAR_10_Image_Classification

Now you can run any projects you want.

---
## ğŸ¤ Collaborators
[Kian Majlessi](https://github.com/kianmajl) and [Audrina Ebrahimi](https://github.com/audrina-ebrahimi)
